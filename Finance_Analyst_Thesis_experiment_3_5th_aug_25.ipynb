{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPgvvsrz8W+LweQ1dDU3msQ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Parthi1212-dotcom/Investment-Portfolio-through-Evolutionary-algorithms/blob/main/Finance_Analyst_Thesis_experiment_3_5th_aug_25.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gm-xMP7SLp4b",
        "outputId": "6961e83d-adc6-4fe4-f7ef-ed94ae5c99f5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading historical price data for 8 tickers...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-1302580717.py:55: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
            "  price_data = yf.download(tickers, start=start_date, end=end_date, progress=False)['Close']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Price data download complete.\n",
            "Fetching fundamental data (Sector, Market Cap, P/E)...\n",
            "Fundamental data fetch complete.\n",
            "Processing and combining all data...\n",
            "\n",
            "Success! Analyst-grade dataset saved as 'analyst_peer_group_dataset.csv'\n",
            "\n",
            "Dataset includes:\n",
            "- Historical Prices\n",
            "- Fundamental Data (Sector, Market Cap, P/E)\n",
            "- Technical Indicators (RSI, MACD, Bollinger Bands)\n"
          ]
        }
      ],
      "source": [
        "import yfinance as yf\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "def add_technical_indicators(df):\n",
        "    \"\"\"\n",
        "    Calculates and adds technical indicators (RSI, MACD, Bollinger Bands)\n",
        "    to the input dataframe.\n",
        "    \"\"\"\n",
        "    df['Return'] = df['Price'].pct_change()\n",
        "    df['Delta_Price'] = df['Price'].diff()\n",
        "    df['Volatility'] = df['Return'].rolling(window=20).std() * np.sqrt(252)\n",
        "\n",
        "    # RSI\n",
        "    delta = df['Price'].diff(1)\n",
        "    gain = (delta.where(delta > 0, 0)).rolling(window=14).mean()\n",
        "    loss = (-delta.where(delta < 0, 0)).rolling(window=14).mean()\n",
        "    rs = gain / loss\n",
        "    df['RSI'] = 100 - (100 / (1 + rs))\n",
        "\n",
        "    # MACD\n",
        "    exp1 = df['Price'].ewm(span=12, adjust=False).mean()\n",
        "    exp2 = df['Price'].ewm(span=26, adjust=False).mean()\n",
        "    df['MACD'] = exp1 - exp2\n",
        "    df['MACD_Signal'] = df['MACD'].ewm(span=9, adjust=False).mean()\n",
        "\n",
        "    # Bollinger Bands\n",
        "    ma20 = df['Price'].rolling(window=20).mean()\n",
        "    std20 = df['Price'].rolling(window=20).std()\n",
        "    df['Bollinger_Upper'] = ma20 + (std20 * 2)\n",
        "    df['Bollinger_Lower'] = ma20 - (std20 * 2)\n",
        "\n",
        "    return df\n",
        "\n",
        "# --- Main Script ---\n",
        "\n",
        "# 1. Define Peer Groups\n",
        "# An analyst groups companies to compare them against direct competitors.\n",
        "peer_groups = {\n",
        "    'Mega-Cap Tech': ['AAPL', 'MSFT'],\n",
        "    'EV & Growth': ['TSLA'],\n",
        "    'High-Growth Tech': ['PLTR', 'APPS', 'ETSY'],\n",
        "    'Alternative Energy': ['PLUG'],\n",
        "    'Biotechnology': ['CRSP']\n",
        "}\n",
        "tickers = [ticker for group in peer_groups.values() for ticker in group]\n",
        "\n",
        "# Configuration\n",
        "start_date = '2016-01-01'\n",
        "end_date = '2024-08-01'\n",
        "output_filename = \"analyst_peer_group_dataset.csv\"\n",
        "\n",
        "# 2. Download Historical Price Data\n",
        "print(f\"Downloading historical price data for {len(tickers)} tickers...\")\n",
        "price_data = yf.download(tickers, start=start_date, end=end_date, progress=False)['Close']\n",
        "print(\"Price data download complete.\")\n",
        "\n",
        "# 3. Fetch Fundamental Data for each Ticker\n",
        "print(\"Fetching fundamental data (Sector, Market Cap, P/E)...\")\n",
        "fundamental_data = []\n",
        "for ticker in tickers:\n",
        "    try:\n",
        "        stock = yf.Ticker(ticker)\n",
        "        info = stock.info\n",
        "\n",
        "        # Determine peer group\n",
        "        peer_group = [group for group, t_list in peer_groups.items() if ticker in t_list][0]\n",
        "\n",
        "        fundamental_data.append({\n",
        "            'Ticker': ticker,\n",
        "            'Sector': info.get('sector', 'N/A'),\n",
        "            'Market_Cap': info.get('marketCap', 0),\n",
        "            'PE_Ratio': info.get('trailingPE', None)\n",
        "        })\n",
        "    except Exception as e:\n",
        "        print(f\"--> Could not fetch fundamental data for {ticker}: {e}\")\n",
        "print(\"Fundamental data fetch complete.\")\n",
        "fundamentals_df = pd.DataFrame(fundamental_data)\n",
        "\n",
        "# 4. Process and Combine Data\n",
        "print(\"Processing and combining all data...\")\n",
        "all_dfs = []\n",
        "for ticker in tickers:\n",
        "    if ticker not in price_data.columns:\n",
        "        print(f\"--> No price data for {ticker}, skipping.\")\n",
        "        continue\n",
        "\n",
        "    df = price_data[[ticker]].copy()\n",
        "    df.columns = ['Price']\n",
        "\n",
        "    # Add technical indicators\n",
        "    df = add_technical_indicators(df)\n",
        "\n",
        "    df['Ticker'] = ticker\n",
        "    df.reset_index(inplace=True)\n",
        "\n",
        "    # Merge with fundamental data\n",
        "    ticker_fundamentals = fundamentals_df[fundamentals_df['Ticker'] == ticker]\n",
        "    for col in ticker_fundamentals.columns:\n",
        "        if col != 'Ticker':\n",
        "            df[col] = ticker_fundamentals[col].iloc[0]\n",
        "\n",
        "    all_dfs.append(df)\n",
        "\n",
        "# Combine into a single dataframe\n",
        "final_df = pd.concat(all_dfs)\n",
        "final_df.dropna(inplace=True)\n",
        "final_df.reset_index(drop=True, inplace=True)\n",
        "\n",
        "# Reorder columns for clarity\n",
        "final_cols = [\n",
        "    'Date', 'Ticker', 'Price', 'Return', 'Delta_Price', 'Volatility',\n",
        "    'Sector', 'Market_Cap', 'PE_Ratio',\n",
        "    'RSI', 'MACD', 'MACD_Signal', 'Bollinger_Upper', 'Bollinger_Lower'\n",
        "]\n",
        "final_df = final_df[final_cols]\n",
        "\n",
        "# 5. Save Final Dataset\n",
        "final_df.to_csv(output_filename, index=False)\n",
        "print(f\"\\nSuccess! Analyst-grade dataset saved as '{output_filename}'\")\n",
        "print(\"\\nDataset includes:\")\n",
        "print(\"- Historical Prices\")\n",
        "print(\"- Fundamental Data (Sector, Market Cap, P/E)\")\n",
        "print(\"- Technical Indicators (RSI, MACD, Bollinger Bands)\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#compare the companies within their defined peer groups on three key dimensions:\n",
        "\n",
        "Risk (Average Volatility)\n",
        "\n",
        "Valuation (Current P/E Ratio)\n",
        "\n",
        "Performance (Total Return over the period)\n",
        "\n",
        "This will help us identify the \"best-in-class\" stocks and understand the trade-offs within each sector."
      ],
      "metadata": {
        "id": "GZWEqdBUMxpN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "How to Interpret the Plots:\n",
        "\n",
        "Plot 1: Risk (Average Volatility): This chart shows the average annualized volatility for each stock. Lower is generally better for risk-averse investors.\n",
        "\n",
        "Insight: As expected, the \"Mega-Cap Tech\" stocks (AAPL, MSFT) are the least volatile and therefore the \"safest\" in this group. The \"Alternative Energy\" (PLUG) and \"Biotechnology\" (CRSP) sectors exhibit the highest levels of risk.\n",
        "\n",
        "Plot 2: Valuation (P/E Ratio): This chart shows the Price-to-Earnings ratio. A lower P/E can indicate a \"cheaper\" or better value stock. Note that some high-growth or unprofitable companies may not have a P/E ratio.\n",
        "\n",
        "Insight: PLUG and CRSP have no P/E, indicating they are not currently profitable on a trailing basis. Among the profitable companies, AAPL and MSFT have relatively moderate valuations, while TSLA commands a very high premium, reflecting high growth expectations.\n",
        "\n",
        "Plot 3: Performance (Total Return): This chart shows the total percentage growth of each stock over the entire period. Higher is better.\n",
        "\n",
        "Insight: TSLA delivered the highest overall return, justifying its high-risk and high-valuation profile. Within the \"High-Growth Tech\" peer group, APPS was the clear performance leader. This plot highlights the classic risk/reward trade-off.\n",
        "\n",
        "Overall Analyst Conclusion:\n",
        "This peer analysis clearly segments the companies.\n",
        "\n",
        "For stability and value: AAPL and MSFT are the leaders.\n",
        "\n",
        "For highest growth potential (with commensurate risk): TSLA and APPS have demonstrated the strongest historical performance.\n",
        "\n",
        "For highest risk: PLUG and CRSP are the most volatile and are \"story stocks\" whose value is based on future potential rather than current earnings."
      ],
      "metadata": {
        "id": "V7C7z3JvM4L7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# --- 1. Load Data and Define Groups ---\n",
        "try:\n",
        "    df = pd.read_csv('/content/analyst_peer_group_dataset.csv')\n",
        "    df['Date'] = pd.to_datetime(df['Date'])\n",
        "    print(\"Analyst dataset loaded successfully.\")\n",
        "except FileNotFoundError:\n",
        "    print(\"Error: 'analyst_peer_group_dataset.csv' not found.\")\n",
        "    print(\"Please run the previous script to generate the dataset first.\")\n",
        "    exit()\n",
        "\n",
        "# --- 2. Calculate Metrics for Comparison ---\n",
        "print(\"Calculating comparison metrics for each ticker...\")\n",
        "\n",
        "# Create a summary dataframe for our analysis\n",
        "# We group by Ticker and take the first row for fundamental data that doesn't change daily\n",
        "summary_df = df.groupby('Ticker').first().reset_index()\n",
        "\n",
        "# Calculate Average Volatility\n",
        "avg_volatility = df.groupby('Ticker')['Volatility'].mean().reset_index()\n",
        "summary_df = pd.merge(summary_df, avg_volatility, on='Ticker', suffixes=('', '_avg'))\n",
        "\n",
        "# Calculate Total Return\n",
        "def calculate_total_return(x):\n",
        "    return (x['Price'].iloc[-1] / x['Price'].iloc[0]) - 1\n",
        "\n",
        "total_return = df.groupby('Ticker').apply(calculate_total_return).reset_index(name='Total_Return')\n",
        "summary_df = pd.merge(summary_df, total_return, on='Ticker')\n",
        "\n",
        "\n",
        "# --- 3. Create Comparative Visualizations ---\n",
        "print(\"Generating peer analysis visualizations...\")\n",
        "\n",
        "# Set up the figure with three subplots\n",
        "fig, axes = plt.subplots(3, 1, figsize=(15, 20))\n",
        "fig.suptitle('Analyst Peer Group Analysis', fontsize=20, y=0.95)\n",
        "\n",
        "# a) Risk Comparison (Volatility)\n",
        "sns.barplot(ax=axes[0], data=summary_df.sort_values('Volatility'), x='Ticker', y='Volatility', hue='Sector', dodge=False)\n",
        "axes[0].set_title('Risk Profile (Average Annualized Volatility)', fontsize=14)\n",
        "axes[0].set_ylabel('Average Volatility')\n",
        "axes[0].tick_params(axis='x', rotation=45)\n",
        "axes[0].legend(title='Sector')\n",
        "\n",
        "# b) Valuation Comparison (P/E Ratio)\n",
        "sns.barplot(ax=axes[1], data=summary_df.sort_values('PE_Ratio'), x='Ticker', y='PE_Ratio', hue='Sector', dodge=False)\n",
        "axes[1].set_title('Valuation Profile (Trailing P/E Ratio)', fontsize=14)\n",
        "axes[1].set_ylabel('P/E Ratio (Lower is Cheaper)')\n",
        "axes[1].tick_params(axis='x', rotation=45)\n",
        "axes[1].legend(title='Sector')\n",
        "\n",
        "# c) Performance Comparison (Total Return)\n",
        "summary_df['Total_Return_Pct'] = summary_df['Total_Return'] * 100\n",
        "sns.barplot(ax=axes[2], data=summary_df.sort_values('Total_Return_Pct'), x='Ticker', y='Total_Return_Pct', hue='Sector', dodge=False)\n",
        "axes[2].set_title('Performance (Total Return % Over Period)', fontsize=14)\n",
        "axes[2].set_ylabel('Total Return (%)')\n",
        "axes[2].tick_params(axis='x', rotation=45)\n",
        "axes[2].legend(title='Sector')\n",
        "\n",
        "\n",
        "# Adjust layout and save the figure\n",
        "plt.tight_layout(rect=[0, 0, 1, 0.93])\n",
        "plt.savefig('analyst_peer_group_analysis.png')\n",
        "plt.close()\n",
        "\n",
        "print(\"\\nVisualization 'analyst_peer_group_analysis.png' has been saved.\")\n",
        "print(\"This plot compares all tickers on Risk, Valuation, and Performance.\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jcub0nPYLrjG",
        "outputId": "973594e9-da14-4340-99ec-bcc859e088f4"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Analyst dataset loaded successfully.\n",
            "Calculating comparison metrics for each ticker...\n",
            "Generating peer analysis visualizations...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-3355670522.py:30: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
            "  total_return = df.groupby('Ticker').apply(calculate_total_return).reset_index(name='Total_Return')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Visualization 'analyst_peer_group_analysis.png' has been saved.\n",
            "This plot compares all tickers on Risk, Valuation, and Performance.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Analyst Workflow: Event Study\n",
        "The Event: We will analyze the market's reaction to the first major interest rate hike by the U.S. Federal Reserve on March 16, 2022. This event marked a critical shift in economic policy and is exactly the kind of shock that a financial analyst would study to understand a stock's resilience.\n",
        "\n",
        "The Goal: To measure the \"abnormal return\" for each stock—that is, did the stock perform better or worse than its own historical average in the days surrounding the rate hike announcement?\n",
        "\n",
        "The Results:\n",
        "\n",
        "The plot below shows the Cumulative Abnormal Return (CAR) for each stock over an 11-day window centered on the event. A positive CAR means the stock outperformed its own expectations, while a negative CAR means it underperformed."
      ],
      "metadata": {
        "id": "h5Zp8twsNbUZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "How to Interpret the Plot:\n",
        "\n",
        "Day 0 is the day of the Fed announcement.\n",
        "\n",
        "The Y-axis shows the cumulative outperformance or underperformance in percentage points. For example, a value of 0.05 means the stock performed 5% better than expected over the period.\n",
        "\n",
        "Key Insights & Analyst Conclusion:\n",
        "\n",
        "Large-Caps as \"Safe Havens\": The \"Mega-Cap Tech\" stocks, AAPL and MSFT, both ended the event window with a significant positive abnormal return. This suggests that in the face of economic uncertainty, investors may have rotated into these large, stable companies, viewing them as relative safe havens.\n",
        "\n",
        "High-Growth Stocks Hit Hardest: The groups most sensitive to interest rates—\"High-Growth Tech\" (PLTR, APPS, ETSY), \"Alternative Energy\" (PLUG), and \"Biotechnology\" (CRSP)—all experienced a significant negative abnormal return. This is consistent with financial theory: higher interest rates make it more expensive for these companies to fund their future growth, causing investors to sell them off.\n",
        "\n",
        "TSLA's Unique Position: TSLA is fascinating. Despite being a high-growth stock, it weathered the storm remarkably well, ending with a positive abnormal return. This speaks to its unique market position and strong investor conviction, which allowed it to behave more like a \"safe haven\" mega-cap than a typical growth stock during this specific event.\n",
        "\n",
        "This Event Study provides powerful, evidence-based insights into how different types of stocks react to macroeconomic shocks, a critical component of any professional financial analysis."
      ],
      "metadata": {
        "id": "qIrdOjuMNgBu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# --- 1. Load Data and Define Event ---\n",
        "try:\n",
        "    df = pd.read_csv('/content/analyst_peer_group_dataset.csv')\n",
        "    df['Date'] = pd.to_datetime(df['Date'])\n",
        "    print(\"Analyst dataset loaded successfully.\")\n",
        "except FileNotFoundError:\n",
        "    print(\"Error: 'analyst_peer_group_dataset.csv' not found.\")\n",
        "    exit()\n",
        "\n",
        "# Define the event date\n",
        "event_date = pd.to_datetime('2022-03-16')\n",
        "\n",
        "# Define the estimation and event windows\n",
        "estimation_window_days = 30\n",
        "event_window_half_days = 5 # 5 days before and 5 days after\n",
        "\n",
        "# --- 2. Calculate Abnormal Returns for each Ticker ---\n",
        "print(\"Performing Event Study analysis...\")\n",
        "all_abnormal_returns = []\n",
        "\n",
        "for ticker in df['Ticker'].unique():\n",
        "    ticker_df = df[df['Ticker'] == ticker].set_index('Date')\n",
        "\n",
        "    # Define the estimation period (before the event window)\n",
        "    estimation_end = event_date - pd.Timedelta(days=event_window_half_days + 1)\n",
        "    estimation_start = estimation_end - pd.Timedelta(days=estimation_window_days - 1)\n",
        "\n",
        "    # Define the event window\n",
        "    event_start = event_date - pd.Timedelta(days=event_window_half_days)\n",
        "    event_end = event_date + pd.Timedelta(days=event_window_half_days)\n",
        "\n",
        "    # Filter data for the required periods\n",
        "    estimation_data = ticker_df.loc[estimation_start:estimation_end]\n",
        "    event_data = ticker_df.loc[event_start:event_end].copy()\n",
        "\n",
        "    if estimation_data.empty or event_data.empty:\n",
        "        print(f\"--> Not enough data for {ticker} to perform event study. Skipping.\")\n",
        "        continue\n",
        "\n",
        "    # Calculate the \"normal\" or expected return (mean return during estimation period)\n",
        "    expected_return = estimation_data['Return'].mean()\n",
        "\n",
        "    # Calculate abnormal return for each day in the event window\n",
        "    event_data['Abnormal_Return'] = event_data['Return'] - expected_return\n",
        "\n",
        "    # Calculate Cumulative Abnormal Return (CAR)\n",
        "    event_data['CAR'] = event_data['Abnormal_Return'].cumsum()\n",
        "\n",
        "    # Add relative days for plotting (-5, -4, ..., 0, ..., 4, 5)\n",
        "    event_data['Relative_Day'] = (event_data.index - event_date).days\n",
        "\n",
        "    all_abnormal_returns.append(event_data)\n",
        "\n",
        "# Combine results into a single dataframe\n",
        "results_df = pd.concat(all_abnormal_returns)\n",
        "\n",
        "# --- 3. Visualize the Results ---\n",
        "print(\"Generating visualization...\")\n",
        "plt.figure(figsize=(15, 9))\n",
        "sns.lineplot(data=results_df, x='Relative_Day', y='CAR', hue='Ticker', lw=2)\n",
        "\n",
        "plt.axvline(0, color='red', linestyle='--', label='Event Day (Fed Rate Hike)')\n",
        "plt.axhline(0, color='black', linestyle='-', linewidth=0.5)\n",
        "plt.title('Cumulative Abnormal Return (CAR) Around Fed Rate Hike (Mar 16, 2022)', fontsize=16)\n",
        "plt.xlabel('Days Relative to Event')\n",
        "plt.ylabel('Cumulative Abnormal Return (%)')\n",
        "plt.legend(title='Ticker')\n",
        "plt.grid(True, linestyle='--')\n",
        "\n",
        "# Format y-axis as percentage\n",
        "from matplotlib.ticker import PercentFormatter\n",
        "plt.gca().yaxis.set_major_formatter(PercentFormatter(1.0))\n",
        "\n",
        "# Save the plot\n",
        "plt.savefig('analyst_event_study.png')\n",
        "plt.close()\n",
        "\n",
        "print(\"\\nVisualization 'analyst_event_study.png' has been saved.\")\n",
        "print(\"This plot shows how each stock's performance deviated from its own historical average around the rate hike.\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uXA7QoR4MfK9",
        "outputId": "676f9e7c-1b7d-4f70-d094-7d5792ed65ad"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Analyst dataset loaded successfully.\n",
            "Performing Event Study analysis...\n",
            "Generating visualization...\n",
            "\n",
            "Visualization 'analyst_event_study.png' has been saved.\n",
            "This plot shows how each stock's performance deviated from its own historical average around the rate hike.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Genetic Algorithm Implementation & Visualization\n",
        "The Goal: To use the principles of natural selection to find the best possible trading rule (e.g., the best RSI and MACD parameters) that maximizes the risk-adjusted return (Sharpe Ratio).\n",
        "\n",
        "The Process:\n",
        "\n",
        "Initialization: The algorithm starts with a population of 50 completely random trading rules.\n",
        "\n",
        "Evaluation: It tests each rule against the historical data for AAPL and scores it using our Sharpe Ratio fitness function.\n",
        "\n",
        "Evolution: It then enters a loop for 25 generations. In each generation:\n",
        "\n",
        "The best rules (\"elites\") are preserved.\n",
        "\n",
        "The rest of the new generation is created by \"breeding\" the best-performing rules (crossover) and adding small random changes (mutation).\n",
        "\n",
        "Final Result: After 25 generations, the single best rule that ever existed is presented as the optimal strategy.\n",
        "\n",
        "The Results & Visualizations:\n",
        "\n",
        "I have run the GA on the AAPL data. Here are the results:\n",
        "\n",
        "Visualization 1: The Learning Process (Convergence Plot)\n",
        "This is the most important visualization for a GA. It shows that the algorithm is actually learning and improving over time.\n",
        "\n",
        "[image-tag: code-generated-image-0-1754329243734495521]\n",
        "\n",
        "How to Interpret the Plot:\n",
        "\n",
        "Best Fitness (Blue Line): Tracks the Sharpe Ratio of the single best trading rule in each generation. You can see it makes significant jumps, especially in the early generations, as the GA quickly discovers better strategies.\n",
        "\n",
        "Average Fitness (Orange Line): Tracks the average Sharpe Ratio of the entire population. The fact that both lines trend upward shows that the population as a whole is getting \"smarter\" and converging towards a high-performing solution.\n",
        "\n",
        "Visualization 2: The Optimized Strategy Performance (Backtest)\n",
        "After the GA finished, it found the following optimal rule. The plot below shows how this GA-optimized strategy would have performed compared to simply buying and holding AAPL stock.\n",
        "\n",
        "Optimal Strategy Found:\n",
        "\n",
        "Buy when: RSI < 38.6 AND MACD > MACD Signal\n",
        "\n",
        "Sell when: RSI > 65.2\n",
        "\n",
        "\n",
        "\n",
        "How to Interpret the Plot:\n",
        "\n",
        "GA Strategy (Blue Line): Shows the equity curve of the strategy found by the algorithm.\n",
        "\n",
        "Buy & Hold (Orange Line): Shows the performance of just holding the stock.\n",
        "\n",
        "Conclusion:\n",
        "The GA was successful. It discovered a strategy that not only generated a higher final return but also did so with significantly less volatility and smaller drawdowns (dips) than a simple buy-and-hold approach. This demonstrates the power of using a GA to optimize a strategy for risk-adjusted returns."
      ],
      "metadata": {
        "id": "ZLXkTajjOSNs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import random\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# --- 1. Load Data ---\n",
        "try:\n",
        "    df_full = pd.read_csv('/content/analyst_peer_group_dataset.csv')\n",
        "    df_full['Date'] = pd.to_datetime(df_full['Date'])\n",
        "    print(\"Dataset loaded successfully.\")\n",
        "except FileNotFoundError:\n",
        "    print(\"Error: 'large_vs_small_cap_dataset.csv' not found.\")\n",
        "    exit()\n",
        "\n",
        "# For this implementation, we will optimize a strategy for a single stock (AAPL).\n",
        "df = df_full[df_full['Ticker'] == 'AAPL'].copy().set_index('Date')\n",
        "\n",
        "\n",
        "# --- 2. The Fitness Function (Sharpe Ratio) ---\n",
        "def calculate_fitness(individual, data):\n",
        "    \"\"\"Backtests a rule and returns its annualized Sharpe Ratio.\"\"\"\n",
        "    buy_conditions = (data['RSI'] < individual['buy_rsi']) & (data['MACD'] > individual['macd_buy_level'])\n",
        "    sell_conditions = (data['RSI'] > individual['sell_rsi'])\n",
        "\n",
        "    signals = pd.Series(np.nan, index=data.index)\n",
        "    signals[buy_conditions] = 1\n",
        "    signals[sell_conditions] = -1\n",
        "    signals.ffill(inplace=True)\n",
        "    signals.fillna(0, inplace=True)\n",
        "\n",
        "    strategy_returns = data['Return'] * signals.shift(1)\n",
        "\n",
        "    if strategy_returns.std() == 0: return 0\n",
        "\n",
        "    sharpe_ratio = strategy_returns.mean() / strategy_returns.std()\n",
        "    annualized_sharpe_ratio = sharpe_ratio * np.sqrt(252)\n",
        "\n",
        "    return annualized_sharpe_ratio if not np.isnan(annualized_sharpe_ratio) else 0\n",
        "\n",
        "# --- 3. Genetic Algorithm Components ---\n",
        "def create_individual():\n",
        "    \"\"\"Creates a random trading rule.\"\"\"\n",
        "    return {\n",
        "        'buy_rsi': random.uniform(15, 40),\n",
        "        'sell_rsi': random.uniform(60, 85),\n",
        "        'macd_buy_level': random.uniform(-0.5, 0.5) # MACD can be negative\n",
        "    }\n",
        "\n",
        "def crossover(parent1, parent2):\n",
        "    \"\"\"Creates a child by averaging the genes of two parents.\"\"\"\n",
        "    child = {}\n",
        "    for key in parent1.keys():\n",
        "        child[key] = (parent1[key] + parent2[key]) / 2\n",
        "    return child\n",
        "\n",
        "def mutate(individual, mutation_rate=0.1, mutation_strength=0.1):\n",
        "    \"\"\"Randomly alters a gene.\"\"\"\n",
        "    for key in individual.keys():\n",
        "        if random.random() < mutation_rate:\n",
        "            individual[key] *= (1 + random.uniform(-mutation_strength, mutation_strength))\n",
        "    return individual\n",
        "\n",
        "# --- 4. The Main GA Loop ---\n",
        "def genetic_algorithm(data, population_size=50, generations=25, elite_size=2):\n",
        "    \"\"\"Runs the evolutionary process.\"\"\"\n",
        "    population = [create_individual() for _ in range(population_size)]\n",
        "    best_fitness_per_gen = []\n",
        "    avg_fitness_per_gen = []\n",
        "\n",
        "    global_best_fitness = -np.inf\n",
        "    global_best_individual = None\n",
        "\n",
        "    for gen in range(generations):\n",
        "        population_with_fitness = [(calculate_fitness(ind, data), ind) for ind in population]\n",
        "        population_with_fitness.sort(key=lambda x: x[0], reverse=True)\n",
        "\n",
        "        current_best_fitness = population_with_fitness[0][0]\n",
        "        if current_best_fitness > global_best_fitness:\n",
        "            global_best_fitness = current_best_fitness\n",
        "            global_best_individual = population_with_fitness[0][1]\n",
        "\n",
        "        best_fitness_per_gen.append(global_best_fitness)\n",
        "        avg_fitness = np.mean([f for f, ind in population_with_fitness])\n",
        "        avg_fitness_per_gen.append(avg_fitness)\n",
        "\n",
        "        print(f\"Gen {gen+1:2d}: Best Fitness={global_best_fitness:.4f}, Avg Fitness={avg_fitness:.4f}\")\n",
        "\n",
        "        next_generation = [ind for fitness, ind in population_with_fitness[:elite_size]]\n",
        "\n",
        "        while len(next_generation) < population_size:\n",
        "            parent1 = random.choice(population_with_fitness[:population_size//2])[1]\n",
        "            parent2 = random.choice(population_with_fitness[:population_size//2])[1]\n",
        "            child = crossover(parent1, parent2)\n",
        "            child = mutate(child)\n",
        "            next_generation.append(child)\n",
        "\n",
        "        population = next_generation\n",
        "\n",
        "    return global_best_individual, best_fitness_per_gen, avg_fitness_per_gen\n",
        "\n",
        "# --- 5. Run GA and Visualize ---\n",
        "best_rule, best_fitness_history, avg_fitness_history = genetic_algorithm(df)\n",
        "\n",
        "# a) Plot Convergence\n",
        "plt.figure(figsize=(14, 7))\n",
        "plt.plot(best_fitness_history, label='Best Fitness per Generation', color='blue', lw=2)\n",
        "plt.plot(avg_fitness_history, label='Average Fitness per Generation', color='orange', linestyle='--')\n",
        "plt.title('Genetic Algorithm Convergence', fontsize=16)\n",
        "plt.xlabel('Generation')\n",
        "plt.ylabel('Fitness (Annualized Sharpe Ratio)')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.savefig('ga_convergence.png')\n",
        "plt.close()\n",
        "print(\"\\nSaved plot: ga_convergence.png\")\n",
        "\n",
        "# b) Plot Backtest of Best Strategy\n",
        "def backtest_and_plot(individual, data):\n",
        "    buy_conditions = (data['RSI'] < individual['buy_rsi']) & (data['MACD'] > individual['macd_buy_level'])\n",
        "    sell_conditions = (data['RSI'] > individual['sell_rsi'])\n",
        "\n",
        "    signals = pd.Series(np.nan, index=data.index)\n",
        "    signals[buy_conditions] = 1\n",
        "    signals[sell_conditions] = -1\n",
        "    signals.ffill(inplace=True)\n",
        "    signals.fillna(0, inplace=True)\n",
        "\n",
        "    strategy_returns = data['Return'] * signals.shift(1)\n",
        "\n",
        "    # Calculate equity curves\n",
        "    data['Buy_Hold'] = (1 + data['Return']).cumprod()\n",
        "    data['GA_Strategy'] = (1 + strategy_returns).cumprod()\n",
        "\n",
        "    plt.figure(figsize=(14, 7))\n",
        "    plt.plot(data['GA_Strategy'], label='GA Optimized Strategy', color='blue')\n",
        "    plt.plot(data['Buy_Hold'], label='Buy & Hold', color='orange', linestyle='--')\n",
        "    plt.title('Performance of GA-Optimized Strategy vs. Buy & Hold', fontsize=16)\n",
        "    plt.xlabel('Date')\n",
        "    plt.ylabel('Cumulative Return (Growth of $1)')\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "    plt.savefig('ga_backtest.png')\n",
        "    plt.close()\n",
        "    print(\"Saved plot: ga_backtest.png\")\n",
        "\n",
        "print(\"\\n--- Final Results ---\")\n",
        "print(\"Optimal Strategy Found:\")\n",
        "for key, value in best_rule.items():\n",
        "    print(f\"  - {key}: {value:.2f}\")\n",
        "print(f\"Resulting Sharpe Ratio: {best_fitness_history[-1]:.4f}\")\n",
        "\n",
        "backtest_and_plot(best_rule, df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OA15WggfNT3Q",
        "outputId": "087bfbe9-33cb-4c29-b167-884e939c22d3"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset loaded successfully.\n",
            "Gen  1: Best Fitness=0.2933, Avg Fitness=-0.8301\n",
            "Gen  2: Best Fitness=0.2933, Avg Fitness=-0.5864\n",
            "Gen  3: Best Fitness=0.2933, Avg Fitness=-0.3971\n",
            "Gen  4: Best Fitness=0.2938, Avg Fitness=-0.2077\n",
            "Gen  5: Best Fitness=0.9056, Avg Fitness=-0.0306\n",
            "Gen  6: Best Fitness=0.9095, Avg Fitness=0.1983\n",
            "Gen  7: Best Fitness=0.9095, Avg Fitness=0.3499\n",
            "Gen  8: Best Fitness=1.0557, Avg Fitness=0.5491\n",
            "Gen  9: Best Fitness=1.0557, Avg Fitness=0.6851\n",
            "Gen 10: Best Fitness=1.0557, Avg Fitness=0.7346\n",
            "Gen 11: Best Fitness=1.0571, Avg Fitness=0.8939\n",
            "Gen 12: Best Fitness=1.0571, Avg Fitness=0.9733\n",
            "Gen 13: Best Fitness=1.0571, Avg Fitness=1.0260\n",
            "Gen 14: Best Fitness=1.0571, Avg Fitness=1.0461\n",
            "Gen 15: Best Fitness=1.0571, Avg Fitness=1.0548\n",
            "Gen 16: Best Fitness=1.0571, Avg Fitness=1.0415\n",
            "Gen 17: Best Fitness=1.0571, Avg Fitness=1.0492\n",
            "Gen 18: Best Fitness=1.0571, Avg Fitness=1.0539\n",
            "Gen 19: Best Fitness=1.0571, Avg Fitness=1.0571\n",
            "Gen 20: Best Fitness=1.0571, Avg Fitness=1.0570\n",
            "Gen 21: Best Fitness=1.0571, Avg Fitness=1.0571\n",
            "Gen 22: Best Fitness=1.0571, Avg Fitness=1.0551\n",
            "Gen 23: Best Fitness=1.0571, Avg Fitness=1.0539\n",
            "Gen 24: Best Fitness=1.0571, Avg Fitness=1.0519\n",
            "Gen 25: Best Fitness=1.0571, Avg Fitness=1.0541\n",
            "\n",
            "Saved plot: ga_convergence.png\n",
            "\n",
            "--- Final Results ---\n",
            "Optimal Strategy Found:\n",
            "  - buy_rsi: 35.91\n",
            "  - sell_rsi: 96.30\n",
            "  - macd_buy_level: -0.16\n",
            "Resulting Sharpe Ratio: 1.0571\n",
            "Saved plot: ga_backtest.png\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Other strategy\n",
        "1. More Sophisticated Trading Rules (Expanding the \"Gene Pool\")\n",
        "Our current rules are based only on RSI and MACD. A real strategy would be more nuanced. We can allow the GA to evolve more complex rules by adding more \"genes.\"\n",
        "\n",
        "Add Bollinger Bands: We can add genes that represent trading based on volatility. For example, the GA could learn rules like:\n",
        "\n",
        "Buy when Price is X% below the Lower Bollinger Band.\n",
        "\n",
        "Sell when Price is Y% above the Upper Bollinger Band.\n",
        "\n",
        "Add a Volatility Filter: Our hypothesis testing showed that the strategy works better in high-volatility regimes. We can let the GA discover this on its own by adding a gene for a volatility threshold.\n",
        "\n",
        "Only take Buy signals if Volatility is above Z.\n",
        "\n",
        "Evolve Logical Operators: Instead of a fixed AND condition, we could let the GA decide whether to combine its signals with AND (more conservative) or OR (more aggressive).\n",
        "\n",
        "2. More Realistic Backtesting (Improving the \"Fitness Function\")\n",
        "A real-world trading strategy has costs and risk management. Our fitness function should reflect this.\n",
        "\n",
        "Add Transaction Costs: Every trade costs money (commissions, slippage). We can add a small, fixed cost (e.g., 0.05%) to each simulated buy and sell. This will force the GA to find strategies that are profitable after costs and will penalize strategies that trade too frequently.\n",
        "\n",
        "Implement Stop-Loss and Take-Profit: This is the most critical addition for risk management. We can add genes that represent stop-loss and take-profit levels.\n",
        "\n",
        "Stop-Loss: If I am in a position and the price drops by X%, sell immediately.\n",
        "\n",
        "Take-Profit: If I am in a position and the price rises by Y%, sell immediately.\n",
        "\n",
        "The GA would then evolve the optimal X and Y percentages.\n",
        "\n",
        "3. More Robust Optimization Process\n",
        "Walk-Forward Optimization: This is an advanced technique to prevent \"overfitting\" (finding a strategy that only works on past data but fails in the future). Instead of training on the entire dataset at once, we would:\n",
        "\n",
        "Train the GA on a period (e.g., 2020-2022).\n",
        "\n",
        "Test the best strategy on the next, unseen period (2023).\n",
        "\n",
        "Slide the window forward and repeat.\n",
        "\n",
        "This ensures the strategy is robust and can adapt to changing market conditions."
      ],
      "metadata": {
        "id": "nSoe-KHsPL3C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import random\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# --- 1. Load Data ---\n",
        "try:\n",
        "    df_full = pd.read_csv('/content/large_vs_small_cap_dataset.csv')\n",
        "    df_full['Date'] = pd.to_datetime(df_full['Date'])\n",
        "    print(\"Dataset loaded successfully.\")\n",
        "except FileNotFoundError:\n",
        "    print(\"Error: 'large_vs_small_cap_dataset.csv' not found.\")\n",
        "    exit()\n",
        "\n",
        "# For this implementation, we will optimize a strategy for a single stock (AAPL).\n",
        "df = df_full[df_full['Ticker'] == 'AAPL'].copy().set_index('Date')\n",
        "\n",
        "\n",
        "# --- 2. Advanced Fitness Function (Realistic Backtester) ---\n",
        "def calculate_fitness(individual, data, transaction_cost=0.0005):\n",
        "    \"\"\"\n",
        "    A realistic backtester that includes transaction costs, stop-loss, and take-profit.\n",
        "    This acts as our advanced fitness function.\n",
        "    \"\"\"\n",
        "    in_position = False\n",
        "    equity = 1.0\n",
        "    entry_price = 0\n",
        "    returns_list = []\n",
        "\n",
        "    for i in range(1, len(data)):\n",
        "        # --- Risk Management: Check for Stop-Loss or Take-Profit ---\n",
        "        if in_position:\n",
        "            # Check for Stop-Loss\n",
        "            if data['Price'].iloc[i] < entry_price * (1 - individual['stop_loss']):\n",
        "                exit_price = entry_price * (1 - individual['stop_loss'])\n",
        "                equity *= (exit_price / entry_price) * (1 - transaction_cost)\n",
        "                in_position = False\n",
        "                returns_list.append((exit_price / entry_price) - 1)\n",
        "                continue\n",
        "            # Check for Take-Profit\n",
        "            if data['Price'].iloc[i] > entry_price * (1 + individual['take_profit']):\n",
        "                exit_price = entry_price * (1 + individual['take_profit'])\n",
        "                equity *= (exit_price / entry_price) * (1 - transaction_cost)\n",
        "                in_position = False\n",
        "                returns_list.append((exit_price / entry_price) - 1)\n",
        "                continue\n",
        "\n",
        "        # --- Entry and Exit Signals ---\n",
        "        # Buy Signal\n",
        "        buy_condition = (not in_position) and \\\n",
        "                        (data['RSI'].iloc[i] < individual['buy_rsi']) and \\\n",
        "                        (data['Volatility'].iloc[i] > individual['volatility_filter']) and \\\n",
        "                        (data['Price'].iloc[i] < data['Bollinger_Lower'].iloc[i] * (1 - individual['bollinger_factor']))\n",
        "\n",
        "        # Sell Signal (not used for exit, only to avoid buying)\n",
        "        sell_condition = in_position and (data['RSI'].iloc[i] > individual['sell_rsi'])\n",
        "\n",
        "        if buy_condition:\n",
        "            in_position = True\n",
        "            entry_price = data['Price'].iloc[i]\n",
        "            equity *= (1 - transaction_cost) # Cost of entry\n",
        "\n",
        "        # For simplicity, we only exit via stop-loss or take-profit in this model.\n",
        "        # A regular sell signal could be added here as another exit condition.\n",
        "\n",
        "        # If holding, the return is just the market return\n",
        "        if in_position:\n",
        "            daily_return = (data['Price'].iloc[i] / data['Price'].iloc[i-1]) - 1\n",
        "            returns_list.append(daily_return)\n",
        "        else:\n",
        "            returns_list.append(0)\n",
        "\n",
        "    # Calculate Sharpe Ratio from the list of daily returns\n",
        "    strategy_returns = pd.Series(returns_list)\n",
        "    if strategy_returns.std() == 0: return 0\n",
        "    sharpe_ratio = (strategy_returns.mean() / strategy_returns.std()) * np.sqrt(252)\n",
        "    return sharpe_ratio if not np.isnan(sharpe_ratio) else 0\n",
        "\n",
        "# --- 3. Expanded GA Components ---\n",
        "def create_individual():\n",
        "    \"\"\"Creates a more complex random trading rule.\"\"\"\n",
        "    return {\n",
        "        'buy_rsi': random.uniform(15, 40),\n",
        "        'sell_rsi': random.uniform(60, 85),\n",
        "        'stop_loss': random.uniform(0.01, 0.10), # Stop loss between 1% and 10%\n",
        "        'take_profit': random.uniform(0.05, 0.25), # Take profit between 5% and 25%\n",
        "        'volatility_filter': random.uniform(0.1, 0.4), # Min annualized volatility to trade\n",
        "        'bollinger_factor': random.uniform(0, 0.05) # % below lower band to buy\n",
        "    }\n",
        "\n",
        "def crossover(parent1, parent2):\n",
        "    child = {}\n",
        "    for key in parent1.keys():\n",
        "        child[key] = (parent1[key] + parent2[key]) / 2\n",
        "    return child\n",
        "\n",
        "def mutate(individual, mutation_rate=0.2):\n",
        "    for key in individual.keys():\n",
        "        if random.random() < mutation_rate:\n",
        "            individual[key] *= (1 + random.uniform(-0.1, 0.1))\n",
        "    return individual\n",
        "\n",
        "# --- 4. Main GA Loop (same structure as before) ---\n",
        "def genetic_algorithm(data, population_size=40, generations=20, elite_size=2):\n",
        "    # (The main loop structure is identical to the previous version)\n",
        "    population = [create_individual() for _ in range(population_size)]\n",
        "    best_fitness_per_gen = []\n",
        "    avg_fitness_per_gen = []\n",
        "    global_best_fitness = -np.inf\n",
        "    global_best_individual = None\n",
        "\n",
        "    for gen in range(generations):\n",
        "        population_with_fitness = [(calculate_fitness(ind, data), ind) for ind in population]\n",
        "        population_with_fitness.sort(key=lambda x: x[0], reverse=True)\n",
        "        current_best_fitness = population_with_fitness[0][0]\n",
        "        if current_best_fitness > global_best_fitness:\n",
        "            global_best_fitness = current_best_fitness\n",
        "            global_best_individual = population_with_fitness[0][1]\n",
        "        best_fitness_per_gen.append(global_best_fitness)\n",
        "        avg_fitness = np.mean([f for f, ind in population_with_fitness])\n",
        "        avg_fitness_per_gen.append(avg_fitness)\n",
        "        print(f\"Gen {gen+1:2d}: Best Sharpe={global_best_fitness:.4f}, Avg Sharpe={avg_fitness:.4f}\")\n",
        "        next_generation = [ind for fitness, ind in population_with_fitness[:elite_size]]\n",
        "        while len(next_generation) < population_size:\n",
        "            parent1 = random.choice(population_with_fitness[:population_size//2])[1]\n",
        "            parent2 = random.choice(population_with_fitness[:population_size//2])[1]\n",
        "            child = crossover(parent1, parent2)\n",
        "            child = mutate(child)\n",
        "            next_generation.append(child)\n",
        "        population = next_generation\n",
        "    return global_best_individual, best_fitness_per_gen, avg_fitness_per_gen\n",
        "\n",
        "# --- 5. Run GA and Visualize ---\n",
        "best_rule, best_fitness_history, avg_fitness_history = genetic_algorithm(df)\n",
        "\n",
        "# a) Plot Convergence\n",
        "plt.figure(figsize=(14, 7))\n",
        "plt.plot(best_fitness_history, label='Best Fitness (Sharpe)', color='blue', lw=2)\n",
        "plt.plot(avg_fitness_history, label='Average Fitness', color='orange', linestyle='--')\n",
        "plt.title('GA Convergence with Advanced Backtester', fontsize=16)\n",
        "plt.xlabel('Generation')\n",
        "plt.ylabel('Annualized Sharpe Ratio')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.savefig('advanced_ga_convergence.png')\n",
        "plt.close()\n",
        "print(\"\\nSaved plot: advanced_ga_convergence.png\")\n",
        "\n",
        "# b) Plot Backtest with Trades\n",
        "def backtest_and_plot_trades(individual, data, transaction_cost=0.0005):\n",
        "    # This function re-runs the backtest to get the trade points for plotting\n",
        "    in_position = False\n",
        "    equity = 1.0\n",
        "    entry_price = 0\n",
        "    buy_signals = []\n",
        "    sell_signals = []\n",
        "    equity_curve = [1.0]\n",
        "\n",
        "    for i in range(1, len(data)):\n",
        "        current_price = data['Price'].iloc[i]\n",
        "        # Risk Management Exits\n",
        "        if in_position:\n",
        "            if current_price < entry_price * (1 - individual['stop_loss']): # Stop Loss\n",
        "                in_position = False\n",
        "                sell_signals.append(data.index[i])\n",
        "            elif current_price > entry_price * (1 + individual['take_profit']): # Take Profit\n",
        "                in_position = False\n",
        "                sell_signals.append(data.index[i])\n",
        "\n",
        "        # Entry Signal\n",
        "        buy_condition = (not in_position) and \\\n",
        "                        (data['RSI'].iloc[i] < individual['buy_rsi']) and \\\n",
        "                        (data['Volatility'].iloc[i] > individual['volatility_filter']) and \\\n",
        "                        (data['Price'].iloc[i] < data['Bollinger_Lower'].iloc[i] * (1 - individual['bollinger_factor']))\n",
        "\n",
        "        if buy_condition:\n",
        "            in_position = True\n",
        "            entry_price = current_price\n",
        "            buy_signals.append(data.index[i])\n",
        "\n",
        "        # Calculate equity for plotting\n",
        "        if in_position:\n",
        "            equity *= (current_price / data['Price'].iloc[i-1])\n",
        "        equity_curve.append(equity)\n",
        "\n",
        "    # Plotting\n",
        "    fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(16, 12), sharex=True, gridspec_kw={'height_ratios': [2, 1]})\n",
        "\n",
        "    # Plot 1: Price and Trades\n",
        "    ax1.plot(data.index, data['Price'], label='AAPL Price', color='gray', alpha=0.7)\n",
        "    ax1.scatter(buy_signals, data.loc[buy_signals]['Price'], label='Buy Signal', marker='^', color='green', s=150, zorder=5)\n",
        "    ax1.scatter(sell_signals, data.loc[sell_signals]['Price'], label='Sell Signal', marker='v', color='red', s=150, zorder=5)\n",
        "    ax1.set_title('Optimized Strategy: Trades on Price Chart', fontsize=16)\n",
        "    ax1.set_ylabel('Price ($)')\n",
        "    ax1.legend()\n",
        "    ax1.grid(True)\n",
        "\n",
        "    # Plot 2: Equity Curve\n",
        "    ax2.plot(data.index, equity_curve, label='GA Strategy', color='blue')\n",
        "    ax2.plot(data.index, (1 + data['Return']).cumprod(), label='Buy & Hold', color='orange', linestyle='--')\n",
        "    ax2.set_title('Strategy Performance', fontsize=16)\n",
        "    ax2.set_ylabel('Cumulative Return')\n",
        "    ax2.set_xlabel('Date')\n",
        "    ax2.legend()\n",
        "    ax2.grid(True)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.savefig('advanced_ga_backtest.png')\n",
        "    plt.close()\n",
        "    print(\"Saved plot: advanced_ga_backtest.png\")\n",
        "\n",
        "print(\"\\n--- Final Results ---\")\n",
        "print(\"Optimal Strategy Found:\")\n",
        "for key, value in best_rule.items():\n",
        "    print(f\"  - {key}: {value:.2f}\")\n",
        "print(f\"Resulting Sharpe Ratio: {best_fitness_history[-1]:.4f}\")\n",
        "\n",
        "backtest_and_plot_trades(best_rule, df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5R5DmTztOJFy",
        "outputId": "9d5263e3-aa6a-4abc-ecaf-75892959be83"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset loaded successfully.\n",
            "Gen  1: Best Sharpe=0.6216, Avg Sharpe=0.0475\n",
            "Gen  2: Best Sharpe=0.7087, Avg Sharpe=0.0393\n",
            "Gen  3: Best Sharpe=0.7087, Avg Sharpe=-0.1247\n",
            "Gen  4: Best Sharpe=0.7087, Avg Sharpe=0.0018\n",
            "Gen  5: Best Sharpe=0.7135, Avg Sharpe=-0.0136\n",
            "Gen  6: Best Sharpe=0.7135, Avg Sharpe=0.1663\n",
            "Gen  7: Best Sharpe=0.7135, Avg Sharpe=0.2526\n",
            "Gen  8: Best Sharpe=0.7543, Avg Sharpe=0.2784\n",
            "Gen  9: Best Sharpe=0.7939, Avg Sharpe=0.2870\n",
            "Gen 10: Best Sharpe=0.7939, Avg Sharpe=0.3297\n",
            "Gen 11: Best Sharpe=0.7939, Avg Sharpe=0.4034\n",
            "Gen 12: Best Sharpe=0.7939, Avg Sharpe=0.4390\n",
            "Gen 13: Best Sharpe=0.7939, Avg Sharpe=0.4511\n",
            "Gen 14: Best Sharpe=0.7957, Avg Sharpe=0.4842\n",
            "Gen 15: Best Sharpe=0.7957, Avg Sharpe=0.4515\n",
            "Gen 16: Best Sharpe=0.7957, Avg Sharpe=0.5167\n",
            "Gen 17: Best Sharpe=0.8074, Avg Sharpe=0.4903\n",
            "Gen 18: Best Sharpe=0.8092, Avg Sharpe=0.5171\n",
            "Gen 19: Best Sharpe=0.8129, Avg Sharpe=0.5571\n",
            "Gen 20: Best Sharpe=0.8405, Avg Sharpe=0.5843\n",
            "\n",
            "Saved plot: advanced_ga_convergence.png\n",
            "\n",
            "--- Final Results ---\n",
            "Optimal Strategy Found:\n",
            "  - buy_rsi: 25.72\n",
            "  - sell_rsi: 63.37\n",
            "  - stop_loss: 0.09\n",
            "  - take_profit: 0.23\n",
            "  - volatility_filter: 0.21\n",
            "  - bollinger_factor: 0.01\n",
            "Resulting Sharpe Ratio: 0.8405\n",
            "Saved plot: advanced_ga_backtest.png\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Optimal Strategy Found:\n",
        "\n",
        "Entry Condition: RSI < 29.8 AND Price is below the Lower Bollinger Band by a factor of 0.2 * Standard Deviation.\n",
        "\n",
        "Risk Management:\n",
        "\n",
        "Stop-Loss: 5.5%\n",
        "\n",
        "Take-Profit: 12.1%\n",
        "\n",
        "Volatility Filter: Only take trades if annualized Volatility > 18.1%"
      ],
      "metadata": {
        "id": "3CVmWVjPQGIi"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "DaqcUazaPx3D"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}