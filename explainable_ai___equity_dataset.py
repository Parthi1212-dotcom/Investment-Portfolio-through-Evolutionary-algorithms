# -*- coding: utf-8 -*-
"""Explainable AI ---> Equity Dataset

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Ow3KWKQ_ZNj2Su844fLiszpckiWpRZno

#Load and Prepare Data
"""

import pandas as pd

# Load your dataset
df = pd.read_csv('/content/q1_2025_all.csv')
df['Date'] = pd.to_datetime(df['Date'])

# Rank-based composite score (lower is better)
rank_cols = ['McapRank', 'VolatilityRank', 'TurnRank', 'PriceRank']
df['CompositeScore'] = df[rank_cols].mean(axis=1)

# Drop rows with missing features
df = df.dropna(subset=["LitVol('000)", "OrderVol('000)", 'OddLots', 'TradesForOddLots', 'Hidden', 'CompositeScore'])

# Select latest date per ticker (one row per asset)
latest_df = df.sort_values('Date').groupby('Ticker').tail(1).set_index('Ticker')

X = latest_df[["LitVol('000)", "OrderVol('000)", 'OddLots', 'TradesForOddLots', 'Hidden']]
y = latest_df['CompositeScore']

print("Shape:", X.shape)
X.head()

from sklearn.ensemble import RandomForestRegressor
from sklearn.model_selection import train_test_split

# Train/test split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Train model
model = RandomForestRegressor(n_estimators=100, random_state=42)
model.fit(X_train, y_train)

# Model performance
print(f"R^2 Score: {model.score(X_test, y_test):.2f}")

import shap

explainer = shap.Explainer(model, X)
shap_values = explainer(X, check_additivity=False)  # Add this flag to skip the check

# Now safe to plot
shap.plots.bar(shap_values, max_display=10)

"""#Visualize Feature Effects

"""

# SHAP summary dot plot
shap.plots.beeswarm(shap_values)

"""#Use SHAP Insights for Portfolio Filtering
Assume:

High 'Hidden' and 'OddLots' increase risk

We want assets with low SHAP values for these
"""

# Create a SHAP impact DataFrame
shap_df = pd.DataFrame(shap_values.values, columns=X.columns, index=X.index)

# Filter tickers where Hidden and OddLots have low impact
safe_assets = shap_df[(shap_df['Hidden'] < 0) & (shap_df['OddLots'] < 0)].index.tolist()

print("Tickers selected based on SHAP safety filter:")
print(safe_assets)

import pandas as pd
import numpy as np

# Load dataset
df = pd.read_csv('/content/q1_2025_all.csv')
df['Date'] = pd.to_datetime(df['Date'])

# Sort for consistency
df = df.sort_values(['Ticker', 'Date'])

# Convert to numeric (some columns might be strings)
cols_to_use = ['TradesForHidden', 'OddLots', 'Cancels']
df[cols_to_use] = df[cols_to_use].apply(pd.to_numeric, errors='coerce')

# Aggregate by date (average across all tickers per day)
daily_micro = df.groupby('Date')[cols_to_use].mean().dropna()

# Rolling window averages (e.g., 5 days)
rolling_window = 5
rolling_avg = daily_micro.rolling(window=rolling_window).mean()

# Simple rule: high hidden activity or odd lots => stressed
hidden_zscore = (rolling_avg['TradesForHidden'] - rolling_avg['TradesForHidden'].mean()) / rolling_avg['TradesForHidden'].std()
oddlot_zscore = (rolling_avg['OddLots'] - rolling_avg['OddLots'].mean()) / rolling_avg['OddLots'].std()
cancel_zscore = (rolling_avg['Cancels'] - rolling_avg['Cancels'].mean()) / rolling_avg['Cancels'].std()

# Combine stress indicators
stress_score = hidden_zscore + oddlot_zscore + cancel_zscore

# Define regimes
regime_label = np.where(stress_score > 1, 'Bear', 'Bull')
rolling_avg['Regime'] = regime_label

import matplotlib.pyplot as plt

plt.figure(figsize=(12, 5))
plt.plot(stress_score.index, stress_score, label='Stress Score')
plt.axhline(1, color='red', linestyle='--', label='Bear Threshold')
plt.fill_between(stress_score.index, stress_score, 1, where=(stress_score > 1), color='red', alpha=0.2, label='Bear Regime')
plt.fill_between(stress_score.index, stress_score, 1, where=(stress_score <= 1), color='green', alpha=0.1, label='Bull Regime')
plt.title("Market Regime Detection Based on Microstructure Stress Score")
plt.xlabel("Date")
plt.ylabel("Score (Z-Scaled)")
plt.legend()
plt.grid(True)
plt.tight_layout()
plt.show()

